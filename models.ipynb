{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj20vpuoNqom"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib widget\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.activations import relu,linear\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "\n",
        "from public_tests_a1 import *\n",
        "\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "from assigment_utils import *\n",
        "\n",
        "tf.autograph.set_verbosity(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y,x_ideal,y_ideal = gen_data(18, 2, 0.7)\n",
        "print(\"X.shape\", X.shape, \"y.shape\", y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=1)\n",
        "print(\"X_train.shape\", X_train.shape, \"y_train.shape\", y_train.shape)\n",
        "print(\"X_test.shape\", X_test.shape, \"y_test.shape\", y_test.shape)"
      ],
      "metadata": {
        "id": "Olu7hof9Nxob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(4,4))\n",
        "ax.plot(x_ideal, y_ideal, \"--\", color = \"orangered\", label=\"y_ideal\", lw=1)\n",
        "ax.set_title(\"Training, Test\",fontsize = 14)\n",
        "ax.set_xlabel(\"x\")\n",
        "ax.set_ylabel(\"y\")\n",
        "\n",
        "ax.scatter(X_train, y_train, color = \"red\",           label=\"train\")\n",
        "ax.scatter(X_test, y_test,   color = dlc[\"dlblue\"],   label=\"test\")\n",
        "ax.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wTotJkZWN1RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_mse(y, yhat):\n",
        "    \"\"\"\n",
        "    Calculate the mean squared error on a data set.\n",
        "    Args:\n",
        "      y    : (ndarray  Shape (m,) or (m,1))  target value of each example\n",
        "      yhat : (ndarray  Shape (m,) or (m,1))  predicted value of each example\n",
        "    Returns:\n",
        "      err: (scalar)\n",
        "    \"\"\"\n",
        "    m = len(y)\n",
        "    err = 0.0\n",
        "    for i in range(m):\n",
        "       err += pow((y[i] - yhat[i]), 2)\n",
        "    err = err/(2*m)\n",
        "\n",
        "    return(err)"
      ],
      "metadata": {
        "id": "1rnN5UA4N2va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model in sklearn, train on training data\n",
        "degree = 10\n",
        "lmodel = lin_model(degree)\n",
        "lmodel.fit(X_train, y_train)\n",
        "\n",
        "# predict on training data, find training error\n",
        "yhat = lmodel.predict(X_train)\n",
        "err_train = lmodel.mse(y_train, yhat)\n",
        "\n",
        "# predict on test data, find error\n",
        "yhat = lmodel.predict(X_test)\n",
        "err_test = lmodel.mse(y_test, yhat)"
      ],
      "metadata": {
        "id": "KLPgZktdN6uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"training err {err_train:0.2f}, test err {err_test:0.2f}\")"
      ],
      "metadata": {
        "id": "snzi0gatN9PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(0,int(X.max()),100)\n",
        "y_pred = lmodel.predict(x).reshape(-1,1)\n",
        "\n",
        "plt_train_test(X_train, y_train, X_test, y_test, x, y_pred, x_ideal, y_ideal, degree)"
      ],
      "metadata": {
        "id": "7iye1z9fN-W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y, x_ideal,y_ideal = gen_data(40, 5, 0.7)\n",
        "print(\"X.shape\", X.shape, \"y.shape\", y.shape)\n",
        "\n",
        "X_train, X_, y_train, y_ = train_test_split(X,y,test_size=0.40, random_state=1)\n",
        "X_cv, X_test, y_cv, y_test = train_test_split(X_,y_,test_size=0.50, random_state=1)\n",
        "print(\"X_train.shape\", X_train.shape, \"y_train.shape\", y_train.shape)\n",
        "print(\"X_cv.shape\", X_cv.shape, \"y_cv.shape\", y_cv.shape)\n",
        "print(\"X_test.shape\", X_test.shape, \"y_test.shape\", y_test.shape)"
      ],
      "metadata": {
        "id": "lk-_DSUXOB96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_degree = 9\n",
        "err_train = np.zeros(max_degree)\n",
        "err_cv = np.zeros(max_degree)\n",
        "x = np.linspace(0,int(X.max()),100)\n",
        "y_pred = np.zeros((100,max_degree))\n",
        "\n",
        "for degree in range(max_degree):\n",
        "    lmodel = lin_model(degree+1)\n",
        "    lmodel.fit(X_train, y_train)\n",
        "    yhat = lmodel.predict(X_train)\n",
        "    err_train[degree] = lmodel.mse(y_train, yhat)\n",
        "    yhat = lmodel.predict(X_cv)\n",
        "    err_cv[degree] = lmodel.mse(y_cv, yhat)\n",
        "    y_pred[:,degree] = lmodel.predict(x)\n",
        "\n",
        "optimal_degree = np.argmin(err_cv)+1"
      ],
      "metadata": {
        "id": "4o9Z7RoeOHg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.close(\"all\")\n",
        "plt_optimal_degree(X_train, y_train, X_cv, y_cv, x, y_pred, x_ideal, y_ideal,\n",
        "                   err_train, err_cv, optimal_degree, max_degree)"
      ],
      "metadata": {
        "id": "JT7xpEupOK7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_range = np.array([0.0, 1e-6, 1e-5, 1e-4,1e-3,1e-2, 1e-1,1,10,100])\n",
        "num_steps = len(lambda_range)\n",
        "degree = 10\n",
        "err_train = np.zeros(num_steps)\n",
        "err_cv = np.zeros(num_steps)\n",
        "x = np.linspace(0,int(X.max()),100)\n",
        "y_pred = np.zeros((100,num_steps))\n",
        "\n",
        "for i in range(num_steps):\n",
        "    lambda_= lambda_range[i]\n",
        "    lmodel = lin_model(degree, regularization=True, lambda_=lambda_)\n",
        "    lmodel.fit(X_train, y_train)\n",
        "    yhat = lmodel.predict(X_train)\n",
        "    err_train[i] = lmodel.mse(y_train, yhat)\n",
        "    yhat = lmodel.predict(X_cv)\n",
        "    err_cv[i] = lmodel.mse(y_cv, yhat)\n",
        "    y_pred[:,i] = lmodel.predict(x)\n",
        "\n",
        "optimal_reg_idx = np.argmin(err_cv)"
      ],
      "metadata": {
        "id": "ncBtJa6QOMsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.close(\"all\")\n",
        "plt_tune_regularization(X_train, y_train, X_cv, y_cv, x, y_pred, err_train, err_cv, optimal_reg_idx, lambda_range)"
      ],
      "metadata": {
        "id": "Ztyk6iI3OT74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_cv, y_cv, x, y_pred, err_train, err_cv, m_range,degree = tune_m()\n",
        "plt_tune_m(X_train, y_train, X_cv, y_cv, x, y_pred, err_train, err_cv, m_range, degree)"
      ],
      "metadata": {
        "id": "mAMCeGDNOcAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, centers, classes, std = gen_blobs()\n",
        "\n",
        "X_train, X_, y_train, y_ = train_test_split(X,y,test_size=0.50, random_state=1)\n",
        "X_cv, X_test, y_cv, y_test = train_test_split(X_,y_,test_size=0.20, random_state=1)\n",
        "print(\"X_train.shape:\", X_train.shape, \"X_cv.shape:\", X_cv.shape, \"X_test.shape:\", X_test.shape)"
      ],
      "metadata": {
        "id": "Q7O3YBTgOc8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_cat_err(y, yhat):\n",
        "    \"\"\"\n",
        "    Calculate the categorization error\n",
        "    Args:\n",
        "      y    : (ndarray  Shape (m,) or (m,1))  target value of each example\n",
        "      yhat : (ndarray  Shape (m,) or (m,1))  predicted value of each example\n",
        "    Returns:|\n",
        "      cerr: (scalar)\n",
        "    \"\"\"\n",
        "    m = len(y)\n",
        "    incorrect = 0\n",
        "    for i in range(m):\n",
        "       if (yhat[i] != y[i]):\n",
        "            incorrect += 1\n",
        "    cerr = incorrect / m\n",
        "\n",
        "    return(cerr)"
      ],
      "metadata": {
        "id": "qgujn4HqOigH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "model = Sequential(\n",
        "    [\n",
        "        Dense(units=120, activation='relu'),\n",
        "        Dense(units=40, activation='relu'),\n",
        "        Dense(units=6, activation='linear')\n",
        "    ], name=\"Complex\"\n",
        ")\n",
        "model.compile(\n",
        "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
        ")"
      ],
      "metadata": {
        "id": "FQEfW50YOm_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=1000\n",
        ")"
      ],
      "metadata": {
        "id": "YrED04FBOtyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_predict = lambda Xl: np.argmax(tf.nn.softmax(model.predict(Xl)).numpy(),axis=1)\n",
        "plt_nn(model_predict,X_train,y_train, classes, X_cv, y_cv, suptitle=\"Complex Model\")"
      ],
      "metadata": {
        "id": "yN8N7R2fOzGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_cerr_complex = eval_cat_err(y_train, model_predict(X_train))\n",
        "cv_cerr_complex = eval_cat_err(y_cv, model_predict(X_cv))\n",
        "print(f\"categorization error, training, complex model: {training_cerr_complex:0.3f}\")\n",
        "print(f\"categorization error, cv,       complex model: {cv_cerr_complex:0.3f}\")"
      ],
      "metadata": {
        "id": "0aYeM2uoOz-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1234)\n",
        "model_s = Sequential(\n",
        "    [\n",
        "        Dense(units=6, activation='relu'),\n",
        "        Dense(units=6, activation='linear')\n",
        "    ], name = \"Simple\"\n",
        ")\n",
        "model_s.compile(\n",
        "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
        ")"
      ],
      "metadata": {
        "id": "bc5ypLtXO1Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_s.fit(\n",
        "    X_train,y_train,\n",
        "    epochs=1000\n",
        ")"
      ],
      "metadata": {
        "id": "0pg-1wk1O6wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_predict_s = lambda Xl: np.argmax(tf.nn.softmax(model_s.predict(Xl)).numpy(),axis=1)\n",
        "plt_nn(model_predict_s,X_train,y_train, classes, X_cv, y_cv, suptitle=\"Simple Model\")"
      ],
      "metadata": {
        "id": "CHfh0cuNO9ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_cerr_simple = eval_cat_err(y_train, model_predict_s(X_train))\n",
        "cv_cerr_simple = eval_cat_err(y_cv, model_predict_s(X_cv))\n",
        "print(f\"categorization error, training, simple model, {training_cerr_simple:0.3f}, complex model: {training_cerr_complex:0.3f}\" )\n",
        "print(f\"categorization error, cv,       simple model, {cv_cerr_simple:0.3f}, complex model: {cv_cerr_complex:0.3f}\" )"
      ],
      "metadata": {
        "id": "1Gb-ArI_O_qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1234)\n",
        "model_r = Sequential(\n",
        "    [\n",
        "        Dense(units=120, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.1)),\n",
        "        Dense(units=40, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.1)),\n",
        "        Dense(units=6, activation='linear')\n",
        "    ], name= None\n",
        ")\n",
        "model_r.compile(\n",
        "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
        ")"
      ],
      "metadata": {
        "id": "HfkJZlRyPA3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_r.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=1000\n",
        ")"
      ],
      "metadata": {
        "id": "Yyn1M8_LPFmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_predict_r = lambda Xl: np.argmax(tf.nn.softmax(model_r.predict(Xl)).numpy(),axis=1)\n",
        "\n",
        "plt_nn(model_predict_r, X_train,y_train, classes, X_cv, y_cv, suptitle=\"Regularized\")"
      ],
      "metadata": {
        "id": "WwMA5nEoPG_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_cerr_reg = eval_cat_err(y_train, model_predict_r(X_train))\n",
        "cv_cerr_reg = eval_cat_err(y_cv, model_predict_r(X_cv))\n",
        "test_cerr_reg = eval_cat_err(y_test, model_predict_r(X_test))\n",
        "print(f\"categorization error, training, regularized: {training_cerr_reg:0.3f}, simple model, {training_cerr_simple:0.3f}, complex model: {training_cerr_complex:0.3f}\" )\n",
        "print(f\"categorization error, cv,       regularized: {cv_cerr_reg:0.3f}, simple model, {cv_cerr_simple:0.3f}, complex model: {cv_cerr_complex:0.3f}\" )"
      ],
      "metadata": {
        "id": "gPMf80RLPKaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1234)\n",
        "lambdas = [0.0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3]\n",
        "models=[None] * len(lambdas)\n",
        "\n",
        "for i in range(len(lambdas)):\n",
        "    lambda_ = lambdas[i]\n",
        "    models[i] =  Sequential(\n",
        "        [\n",
        "            Dense(120, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(lambda_)),\n",
        "            Dense(40, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(lambda_)),\n",
        "            Dense(classes, activation = 'linear')\n",
        "        ]\n",
        "    )\n",
        "    models[i].compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    )\n",
        "\n",
        "    models[i].fit(\n",
        "        X_train,y_train,\n",
        "        epochs=1000\n",
        "    )\n",
        "    print(f\"Finished lambda = {lambda_}\")"
      ],
      "metadata": {
        "id": "pN1VGwOlPOUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_iterate(lambdas, models, X_train, y_train, X_cv, y_cv)"
      ],
      "metadata": {
        "id": "UGtY0LRFPQ99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt_compare(X_test,y_test, classes, model_predict_s, model_predict_r, centers)"
      ],
      "metadata": {
        "id": "W5hKMLBQPT5Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}